{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.nb.stop_words import STOP_WORDS\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path('model')\n",
    "SAVE_PATH.mkdir(exist_ok=True)\n",
    "DATA_PATH = Path('../data/norec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = ['train', 'test', 'dev']\n",
    "subsets = {name: pd.read_pickle(DATA_PATH / f'norsk_kategori_{name}.pkl') for name in subset_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = subsets['train'].iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"«Poison». Som alle store artister passer Timberlake på å synliggjøre hvor han kommer fra musikalsk.. Derav denne relativt obskure new jack swing-saken fra Bell Biv DeVoe, gruppen som ble til New Edition og som sådan forløpere til N'Sync.. Fenomenalt frekk låt som skreddersydd for Justin.\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         text\n",
       "rating       \n",
       "0        2326\n",
       "1       11597"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2326</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11597</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "subsets['train'].groupby(['rating']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  rating\n",
       "2676  «Poison». Som alle store artister passer Timbe...       1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2676</th>\n      <td>«Poison». Som alle store artister passer Timbe...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "subsets['train'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=10000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['00', '000', '10', '100', '1000', '1024', '105', '1080', '1080p', '11']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81      2326\n",
      "           1       0.94      1.00      0.97     11597\n",
      "\n",
      "    accuracy                           0.95     13923\n",
      "   macro avg       0.96      0.84      0.89     13923\n",
      "weighted avg       0.95      0.95      0.94     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.50      0.64       230\n",
      "           1       0.93      0.99      0.96      1569\n",
      "\n",
      "    accuracy                           0.93      1799\n",
      "   macro avg       0.91      0.75      0.80      1799\n",
      "weighted avg       0.93      0.93      0.92      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boosted_model = xgb.XGBClassifier()\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80      2326\n",
      "           1       1.00      0.90      0.95     11597\n",
      "\n",
      "    accuracy                           0.92     13923\n",
      "   macro avg       0.83      0.94      0.87     13923\n",
      "weighted avg       0.94      0.92      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.79      0.65       230\n",
      "           1       0.97      0.91      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.85      0.80      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80      2326\n",
      "           1       1.00      0.90      0.95     11597\n",
      "\n",
      "    accuracy                           0.92     13923\n",
      "   macro avg       0.83      0.94      0.87     13923\n",
      "weighted avg       0.94      0.92      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.80      0.64       230\n",
      "           1       0.97      0.90      0.93      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.75      0.85      0.79      1799\n",
      "weighted avg       0.91      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81      2326\n",
      "           1       1.00      0.91      0.95     11597\n",
      "\n",
      "    accuracy                           0.92     13923\n",
      "   macro avg       0.84      0.95      0.88     13923\n",
      "weighted avg       0.94      0.92      0.93     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66       230\n",
      "           1       0.97      0.91      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.86      0.80      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=20000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77      2326\n",
      "           1       0.99      0.89      0.94     11597\n",
      "\n",
      "    accuracy                           0.90     13923\n",
      "   macro avg       0.81      0.93      0.85     13923\n",
      "weighted avg       0.93      0.90      0.91     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.74      0.60       230\n",
      "           1       0.96      0.89      0.93      1569\n",
      "\n",
      "    accuracy                           0.87      1799\n",
      "   macro avg       0.73      0.82      0.76      1799\n",
      "weighted avg       0.90      0.87      0.88      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=1000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "source": [
    "Not much difference in 5000, 10000, 20000 features for XGBoost. With 1000 features however, the result is noticably worse.\n",
    "\n",
    "While it's not overfitting as much as the Logistic Regression, going with 5000 features will make everything faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"«Poison». Som alle store artister passer Timberlake på å synliggjøre hvor han kommer fra musikalsk.. Derav denne relativt obskure new jack swing-saken fra Bell Biv DeVoe, gruppen som ble til New Edition og som sådan forløpere til N'Sync.. Fenomenalt frekk låt som skreddersydd for Justin.\""
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('nb_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "«Poison». Som alle store artister passer Timberlake på å synliggjøre hvor han kommer fra musikalsk.. Derav denne relativt obskure new jack swing-saken fra Bell Biv DeVoe, gruppen som ble til New Edition og som sådan forløpere til N'Sync.. Fenomenalt frekk låt som skreddersydd for Justin."
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"« Poison » . som alle stor artist passere Timberlake på å synliggjøre hvor han komme fra musikalsk .. Derav denne relativ obskur new jack swing-sake fra Bell Biv DeVoe , gruppe som bli til New Edition og som sådan forløper til N'Sync .. fenomenal frekk låt som skreddersy for Justin .\""
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "lemmatised_text = ' '.join([term.lemma_ for term in doc])\n",
    "lemmatised_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\" poison \" . som alle store artister passer timberlake på å synliggjøre hvor han kommer fra musikalsk .. derav denne relativt obskure new jack swing-saken fra bell biv devoe , gruppen som ble til new edition og som sådan forløpere til n\\'sync .. fenomenalt frekk låt som skreddersydd for justin .'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "normed_text = ' '.join([term.norm_ for term in doc])\n",
    "normed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 25.7 ms, sys: 2.32 ms, total: 28 ms\nWall time: 37.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('parser', <spacy.pipeline.pipes.DependencyParser at 0x12b1d1b20>)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "nlp.remove_pipe('ner')\n",
    "nlp.remove_pipe('tagger')\n",
    "nlp.remove_pipe('parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 165 µs, sys: 1 µs, total: 166 µs\nWall time: 174 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniser(text):\n",
    "    return [term.lemma_.lower() for term in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77      2326\n",
      "           1       0.99      0.89      0.94     11597\n",
      "\n",
      "    accuracy                           0.90     13923\n",
      "   macro avg       0.81      0.93      0.85     13923\n",
      "weighted avg       0.93      0.90      0.91     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.75      0.61       230\n",
      "           1       0.96      0.90      0.93      1569\n",
      "\n",
      "    accuracy                           0.88      1799\n",
      "   macro avg       0.74      0.82      0.77      1799\n",
      "weighted avg       0.90      0.88      0.89      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=1000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79      2326\n",
      "           1       1.00      0.90      0.94     11597\n",
      "\n",
      "    accuracy                           0.91     13923\n",
      "   macro avg       0.83      0.94      0.87     13923\n",
      "weighted avg       0.94      0.91      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66       230\n",
      "           1       0.97      0.91      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.86      0.80      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=10000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79      2326\n",
      "           1       1.00      0.90      0.95     11597\n",
      "\n",
      "    accuracy                           0.91     13923\n",
      "   macro avg       0.83      0.94      0.87     13923\n",
      "weighted avg       0.94      0.91      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.80      0.65       230\n",
      "           1       0.97      0.90      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.85      0.79      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79      2326\n",
      "           1       0.99      0.90      0.94     11597\n",
      "\n",
      "    accuracy                           0.91     13923\n",
      "   macro avg       0.83      0.94      0.86     13923\n",
      "weighted avg       0.94      0.91      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.80      0.65       230\n",
      "           1       0.97      0.91      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.85      0.80      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.92      0.60      2326\n",
      "           1       0.98      0.77      0.86     11597\n",
      "\n",
      "    accuracy                           0.79     13923\n",
      "   macro avg       0.71      0.84      0.73     13923\n",
      "weighted avg       0.89      0.79      0.82     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.73      0.44       230\n",
      "           1       0.95      0.77      0.85      1569\n",
      "\n",
      "    accuracy                           0.76      1799\n",
      "   macro avg       0.64      0.75      0.65      1799\n",
      "weighted avg       0.87      0.76      0.80      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=100, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.72      2326\n",
      "           1       0.99      0.86      0.92     11597\n",
      "\n",
      "    accuracy                           0.88     13923\n",
      "   macro avg       0.78      0.91      0.82     13923\n",
      "weighted avg       0.92      0.88      0.89     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.75      0.58       230\n",
      "           1       0.96      0.88      0.92      1569\n",
      "\n",
      "    accuracy                           0.86      1799\n",
      "   macro avg       0.72      0.81      0.75      1799\n",
      "weighted avg       0.90      0.86      0.87      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=500, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.99      0.82      2326\n",
      "           1       1.00      0.92      0.95     11597\n",
      "\n",
      "    accuracy                           0.93     13923\n",
      "   macro avg       0.85      0.95      0.89     13923\n",
      "weighted avg       0.95      0.93      0.93     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.78      0.65       230\n",
      "           1       0.97      0.91      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.84      0.79      1799\n",
      "weighted avg       0.91      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=2000, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79      2326\n",
      "           1       1.00      0.90      0.95     11597\n",
      "\n",
      "    accuracy                           0.91     13923\n",
      "   macro avg       0.83      0.94      0.87     13923\n",
      "weighted avg       0.94      0.91      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.80      0.65       230\n",
      "           1       0.97      0.90      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.85      0.79      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=10, max_df=1000, max_features=5000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79      2326\n",
      "           1       1.00      0.90      0.94     11597\n",
      "\n",
      "    accuracy                           0.91     13923\n",
      "   macro avg       0.83      0.94      0.87     13923\n",
      "weighted avg       0.94      0.91      0.92     13923\n",
      "\n",
      "Development metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.80      0.66       230\n",
      "           1       0.97      0.91      0.94      1569\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.76      0.86      0.80      1799\n",
      "weighted avg       0.92      0.89      0.90      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokeniser, stop_words=STOP_WORDS, min_df=5, max_df=1000, max_features=10000)\n",
    "vectorizer.fit_transform(subsets['train']['text'])\n",
    "texts = {name: vectorizer.transform(subsets[name]['text']) for name in subset_names}\n",
    "categories = {name: subsets[name]['rating'] for name in subset_names}\n",
    "boosted_model = xgb.XGBClassifier(scale_pos_weight=0.2)\n",
    "boosted_model.fit(texts['train'], categories['train'])\n",
    "print('Training metrics')\n",
    "print(classification_report(categories['train'], boosted_model.predict(texts['train'])))\n",
    "print('Development metrics')\n",
    "print(classification_report(categories['dev'], boosted_model.predict(texts['dev'])))"
   ]
  },
  {
   "source": [
    "The conclusion is that the initial min_df=5, max_df=1000 performs best. The optimal feature count seems to be 10000."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('text-oqa78tdt': venv)",
   "metadata": {
    "interpreter": {
     "hash": "b79a91171a1b654441da0aa02197604a6e053331b5ce31ae0001fbbaddbfb627"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}