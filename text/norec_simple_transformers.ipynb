{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, matthews_corrcoef\n",
    "import spacy\n",
    "from spacy.lang.nb.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().isoformat()\n",
    "SAVE_PATH = Path('model')\n",
    "SAVE_PATH.mkdir(exist_ok=True)\n",
    "DATA_PATH = Path('data/norec')\n",
    "DATA_PATH = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = ['train', 'test', 'dev']\n",
    "subsets = {name: pd.read_pickle(DATA_PATH / f'norsk_kategori_{name}.pkl') for name in subset_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         text\n",
       "rating       \n",
       "0        2681\n",
       "1       14821"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2681</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14821</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "subsets['train'].groupby(['rating']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  rating\n",
       "4848  Franz Ferdinand :\\n« You Could Have It So Much...       1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4848</th>\n      <td>Franz Ferdinand :\\n« You Could Have It So Much...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "subsets['train'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  label\n",
       "4848  Franz Ferdinand :\\n« You Could Have It So Much...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4848</th>\n      <td>Franz Ferdinand :\\n« You Could Have It So Much...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "subsets = {name: subsets[name].rename(columns={'rating': 'label'}) for name in subset_names}\n",
    "subsets['train'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(\n",
    "    'distilbert', \n",
    "    'distilbert-base-multilingual-cased', \n",
    "    num_labels=2, \n",
    "    use_cuda=False,\n",
    "    weight=[7, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "9s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3870:  95%|█████████▌| 2082/2188 [4:08:41<10:13,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3870:  95%|█████████▌| 2083/2188 [4:08:46<10:03,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3445:  95%|█████████▌| 2083/2188 [4:08:47<10:03,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3445:  95%|█████████▌| 2084/2188 [4:08:51<09:51,  5.68s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4096:  95%|█████████▌| 2084/2188 [4:08:53<09:51,  5.68s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4096:  95%|█████████▌| 2085/2188 [4:08:57<09:49,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1503:  95%|█████████▌| 2085/2188 [4:08:58<09:49,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1503:  95%|█████████▌| 2086/2188 [4:09:03<09:46,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3600:  95%|█████████▌| 2086/2188 [4:09:04<09:46,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3600:  95%|█████████▌| 2087/2188 [4:09:09<09:40,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3722:  95%|█████████▌| 2087/2188 [4:09:10<09:40,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3722:  95%|█████████▌| 2088/2188 [4:09:14<09:31,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6449:  95%|█████████▌| 2088/2188 [4:09:16<09:31,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6449:  95%|█████████▌| 2089/2188 [4:09:20<09:26,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6302:  95%|█████████▌| 2089/2188 [4:09:21<09:26,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6302:  96%|█████████▌| 2090/2188 [4:09:26<09:23,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1526:  96%|█████████▌| 2090/2188 [4:09:27<09:23,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1526:  96%|█████████▌| 2091/2188 [4:09:32<09:18,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3927:  96%|█████████▌| 2091/2188 [4:09:33<09:18,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3927:  96%|█████████▌| 2092/2188 [4:09:37<09:12,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6063:  96%|█████████▌| 2092/2188 [4:09:39<09:12,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6063:  96%|█████████▌| 2093/2188 [4:09:43<09:04,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0477:  96%|█████████▌| 2093/2188 [4:09:44<09:04,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0477:  96%|█████████▌| 2094/2188 [4:09:49<08:59,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3828:  96%|█████████▌| 2094/2188 [4:09:50<08:59,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3828:  96%|█████████▌| 2095/2188 [4:09:55<08:52,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3711:  96%|█████████▌| 2095/2188 [4:09:56<08:52,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3711:  96%|█████████▌| 2096/2188 [4:10:01<08:53,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1654:  96%|█████████▌| 2096/2188 [4:10:02<08:53,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1654:  96%|█████████▌| 2097/2188 [4:10:06<08:50,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5817:  96%|█████████▌| 2097/2188 [4:10:08<08:50,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5817:  96%|█████████▌| 2098/2188 [4:10:12<08:36,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1655:  96%|█████████▌| 2098/2188 [4:10:13<08:36,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1655:  96%|█████████▌| 2099/2188 [4:10:18<08:31,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1586:  96%|█████████▌| 2099/2188 [4:10:19<08:31,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1586:  96%|█████████▌| 2100/2188 [4:10:23<08:23,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3985:  96%|█████████▌| 2100/2188 [4:10:25<08:23,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3985:  96%|█████████▌| 2101/2188 [4:10:29<08:22,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1446:  96%|█████████▌| 2101/2188 [4:10:31<08:22,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1446:  96%|█████████▌| 2102/2188 [4:10:35<08:15,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1567:  96%|█████████▌| 2102/2188 [4:10:36<08:15,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1567:  96%|█████████▌| 2103/2188 [4:10:41<08:08,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3879:  96%|█████████▌| 2103/2188 [4:10:42<08:08,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3879:  96%|█████████▌| 2104/2188 [4:10:46<08:01,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1480:  96%|█████████▌| 2104/2188 [4:10:48<08:01,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1480:  96%|█████████▌| 2105/2188 [4:10:52<07:58,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1501:  96%|█████████▌| 2105/2188 [4:10:54<07:58,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1501:  96%|█████████▋| 2106/2188 [4:10:58<07:58,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1515:  96%|█████████▋| 2106/2188 [4:11:00<07:58,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1515:  96%|█████████▋| 2107/2188 [4:11:05<08:08,  6.03s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6047:  96%|█████████▋| 2107/2188 [4:11:06<08:08,  6.03s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6047:  96%|█████████▋| 2108/2188 [4:11:10<07:54,  5.93s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3941:  96%|█████████▋| 2108/2188 [4:11:12<07:54,  5.93s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3941:  96%|█████████▋| 2109/2188 [4:11:16<07:43,  5.87s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5902:  96%|█████████▋| 2109/2188 [4:11:17<07:43,  5.87s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5902:  96%|█████████▋| 2110/2188 [4:11:22<07:36,  5.85s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3844:  96%|█████████▋| 2110/2188 [4:11:23<07:36,  5.85s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3844:  96%|█████████▋| 2111/2188 [4:11:28<07:30,  5.85s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1456:  96%|█████████▋| 2111/2188 [4:11:29<07:30,  5.85s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1456:  97%|█████████▋| 2112/2188 [4:11:34<07:26,  5.88s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3837:  97%|█████████▋| 2112/2188 [4:11:35<07:26,  5.88s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3837:  97%|█████████▋| 2113/2188 [4:11:40<07:19,  5.86s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3765:  97%|█████████▋| 2113/2188 [4:11:41<07:19,  5.86s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3765:  97%|█████████▋| 2114/2188 [4:11:45<07:10,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3761:  97%|█████████▋| 2114/2188 [4:11:47<07:10,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3761:  97%|█████████▋| 2115/2188 [4:11:51<07:02,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6257:  97%|█████████▋| 2115/2188 [4:11:52<07:02,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6257:  97%|█████████▋| 2116/2188 [4:11:57<06:58,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3709:  97%|█████████▋| 2116/2188 [4:11:58<06:58,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3709:  97%|█████████▋| 2117/2188 [4:12:03<06:54,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1458:  97%|█████████▋| 2117/2188 [4:12:04<06:54,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1458:  97%|█████████▋| 2118/2188 [4:12:09<06:49,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6183:  97%|█████████▋| 2118/2188 [4:12:10<06:49,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6183:  97%|█████████▋| 2119/2188 [4:12:14<06:42,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3968:  97%|█████████▋| 2119/2188 [4:12:16<06:42,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3968:  97%|█████████▋| 2120/2188 [4:12:20<06:34,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1432:  97%|█████████▋| 2120/2188 [4:12:21<06:34,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1432:  97%|█████████▋| 2121/2188 [4:12:26<06:29,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5645:  97%|█████████▋| 2121/2188 [4:12:27<06:29,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5645:  97%|█████████▋| 2122/2188 [4:12:32<06:23,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3914:  97%|█████████▋| 2122/2188 [4:12:33<06:23,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3914:  97%|█████████▋| 2123/2188 [4:12:38<06:17,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5978:  97%|█████████▋| 2123/2188 [4:12:39<06:17,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5978:  97%|█████████▋| 2124/2188 [4:12:43<06:08,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3718:  97%|█████████▋| 2124/2188 [4:12:45<06:08,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3718:  97%|█████████▋| 2125/2188 [4:12:49<05:59,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1508:  97%|█████████▋| 2125/2188 [4:12:50<05:59,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1508:  97%|█████████▋| 2126/2188 [4:12:55<05:53,  5.70s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3705:  97%|█████████▋| 2126/2188 [4:12:56<05:53,  5.70s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3705:  97%|█████████▋| 2127/2188 [4:13:00<05:51,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5912:  97%|█████████▋| 2127/2188 [4:13:02<05:51,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5912:  97%|█████████▋| 2128/2188 [4:13:06<05:47,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6248:  97%|█████████▋| 2128/2188 [4:13:08<05:47,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6248:  97%|█████████▋| 2129/2188 [4:13:12<05:40,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3813:  97%|█████████▋| 2129/2188 [4:13:13<05:40,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3813:  97%|█████████▋| 2130/2188 [4:13:18<05:31,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3509:  97%|█████████▋| 2130/2188 [4:13:19<05:31,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3509:  97%|█████████▋| 2131/2188 [4:13:23<05:25,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1455:  97%|█████████▋| 2131/2188 [4:13:25<05:25,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1455:  97%|█████████▋| 2132/2188 [4:13:29<05:23,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3591:  97%|█████████▋| 2132/2188 [4:13:31<05:23,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3591:  97%|█████████▋| 2133/2188 [4:13:35<05:20,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6113:  97%|█████████▋| 2133/2188 [4:13:37<05:20,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6113:  98%|█████████▊| 2134/2188 [4:13:41<05:12,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5873:  98%|█████████▊| 2134/2188 [4:13:42<05:12,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5873:  98%|█████████▊| 2135/2188 [4:13:47<05:05,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1502:  98%|█████████▊| 2135/2188 [4:13:48<05:05,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1502:  98%|█████████▊| 2136/2188 [4:13:52<04:57,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3655:  98%|█████████▊| 2136/2188 [4:13:54<04:57,  5.72s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3655:  98%|█████████▊| 2137/2188 [4:13:58<04:54,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1395:  98%|█████████▊| 2137/2188 [4:13:59<04:54,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1395:  98%|█████████▊| 2138/2188 [4:14:04<04:48,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3640:  98%|█████████▊| 2138/2188 [4:14:05<04:48,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3640:  98%|█████████▊| 2139/2188 [4:14:09<04:39,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3886:  98%|█████████▊| 2139/2188 [4:14:11<04:39,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3886:  98%|█████████▊| 2140/2188 [4:14:15<04:33,  5.70s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6154:  98%|█████████▊| 2140/2188 [4:14:16<04:33,  5.70s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6154:  98%|█████████▊| 2141/2188 [4:14:21<04:28,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3724:  98%|█████████▊| 2141/2188 [4:14:22<04:28,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3724:  98%|█████████▊| 2142/2188 [4:14:27<04:24,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1084:  98%|█████████▊| 2142/2188 [4:14:28<04:24,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1084:  98%|█████████▊| 2143/2188 [4:14:33<04:21,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1471:  98%|█████████▊| 2143/2188 [4:14:34<04:21,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1471:  98%|█████████▊| 2144/2188 [4:14:38<04:15,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8563:  98%|█████████▊| 2144/2188 [4:14:40<04:15,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8563:  98%|█████████▊| 2145/2188 [4:14:44<04:09,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3848:  98%|█████████▊| 2145/2188 [4:14:46<04:09,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3848:  98%|█████████▊| 2146/2188 [4:14:50<04:02,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5997:  98%|█████████▊| 2146/2188 [4:14:51<04:02,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5997:  98%|█████████▊| 2147/2188 [4:14:56<03:56,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6031:  98%|█████████▊| 2147/2188 [4:14:57<03:56,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6031:  98%|█████████▊| 2148/2188 [4:15:02<03:52,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3795:  98%|█████████▊| 2148/2188 [4:15:03<03:52,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3795:  98%|█████████▊| 2149/2188 [4:15:07<03:47,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4035:  98%|█████████▊| 2149/2188 [4:15:09<03:47,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4035:  98%|█████████▊| 2150/2188 [4:15:13<03:40,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3753:  98%|█████████▊| 2150/2188 [4:15:14<03:40,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3753:  98%|█████████▊| 2151/2188 [4:15:19<03:33,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1444:  98%|█████████▊| 2151/2188 [4:15:20<03:33,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1444:  98%|█████████▊| 2152/2188 [4:15:25<03:28,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8533:  98%|█████████▊| 2152/2188 [4:15:26<03:28,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8533:  98%|█████████▊| 2153/2188 [4:15:31<03:23,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3970:  98%|█████████▊| 2153/2188 [4:15:32<03:23,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3970:  98%|█████████▊| 2154/2188 [4:15:37<03:18,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3667:  98%|█████████▊| 2154/2188 [4:15:38<03:18,  5.83s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3667:  98%|█████████▊| 2155/2188 [4:15:42<03:10,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3706:  98%|█████████▊| 2155/2188 [4:15:44<03:10,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3706:  99%|█████████▊| 2156/2188 [4:15:48<03:06,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8448:  99%|█████████▊| 2156/2188 [4:15:49<03:06,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8448:  99%|█████████▊| 2157/2188 [4:15:54<02:59,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6358:  99%|█████████▊| 2157/2188 [4:15:55<02:59,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6358:  99%|█████████▊| 2158/2188 [4:16:00<02:54,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1369:  99%|█████████▊| 2158/2188 [4:16:01<02:54,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1369:  99%|█████████▊| 2159/2188 [4:16:05<02:48,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1432:  99%|█████████▊| 2159/2188 [4:16:07<02:48,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1432:  99%|█████████▊| 2160/2188 [4:16:11<02:41,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1484:  99%|█████████▊| 2160/2188 [4:16:12<02:41,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1484:  99%|█████████▉| 2161/2188 [4:16:17<02:34,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1472:  99%|█████████▉| 2161/2188 [4:16:18<02:34,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1472:  99%|█████████▉| 2162/2188 [4:16:23<02:29,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3621:  99%|█████████▉| 2162/2188 [4:16:24<02:29,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3621:  99%|█████████▉| 2163/2188 [4:16:28<02:24,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6112:  99%|█████████▉| 2163/2188 [4:16:30<02:24,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6112:  99%|█████████▉| 2164/2188 [4:16:34<02:19,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1530:  99%|█████████▉| 2164/2188 [4:16:36<02:19,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1530:  99%|█████████▉| 2165/2188 [4:16:40<02:12,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1562:  99%|█████████▉| 2165/2188 [4:16:41<02:12,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1562:  99%|█████████▉| 2166/2188 [4:16:46<02:07,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8541:  99%|█████████▉| 2166/2188 [4:16:47<02:07,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8541:  99%|█████████▉| 2167/2188 [4:16:52<02:02,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3985:  99%|█████████▉| 2167/2188 [4:16:53<02:02,  5.81s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3985:  99%|█████████▉| 2168/2188 [4:16:57<01:56,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5936:  99%|█████████▉| 2168/2188 [4:16:59<01:56,  5.82s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5936:  99%|█████████▉| 2169/2188 [4:17:03<01:49,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5850:  99%|█████████▉| 2169/2188 [4:17:05<01:49,  5.79s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5850:  99%|█████████▉| 2170/2188 [4:17:09<01:45,  5.85s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5827:  99%|█████████▉| 2170/2188 [4:17:10<01:45,  5.85s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5827:  99%|█████████▉| 2171/2188 [4:17:15<01:38,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3961:  99%|█████████▉| 2171/2188 [4:17:16<01:38,  5.77s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3961:  99%|█████████▉| 2172/2188 [4:17:20<01:31,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1500:  99%|█████████▉| 2172/2188 [4:17:22<01:31,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1500:  99%|█████████▉| 2173/2188 [4:17:26<01:26,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3625:  99%|█████████▉| 2173/2188 [4:17:28<01:26,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3625:  99%|█████████▉| 2174/2188 [4:17:32<01:20,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6071:  99%|█████████▉| 2174/2188 [4:17:33<01:20,  5.78s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6071:  99%|█████████▉| 2175/2188 [4:17:38<01:14,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1486:  99%|█████████▉| 2175/2188 [4:17:39<01:14,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1486:  99%|█████████▉| 2176/2188 [4:17:43<01:08,  5.70s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3770:  99%|█████████▉| 2176/2188 [4:17:45<01:08,  5.70s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3770:  99%|█████████▉| 2177/2188 [4:17:49<01:02,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5951:  99%|█████████▉| 2177/2188 [4:17:50<01:02,  5.71s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5951: 100%|█████████▉| 2178/2188 [4:17:55<00:57,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1521: 100%|█████████▉| 2178/2188 [4:17:56<00:57,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1521: 100%|█████████▉| 2179/2188 [4:18:01<00:51,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8615: 100%|█████████▉| 2179/2188 [4:18:02<00:51,  5.76s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8615: 100%|█████████▉| 2180/2188 [4:18:07<00:46,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3890: 100%|█████████▉| 2180/2188 [4:18:08<00:46,  5.80s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3890: 100%|█████████▉| 2181/2188 [4:18:12<00:40,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5799: 100%|█████████▉| 2181/2188 [4:18:14<00:40,  5.74s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5799: 100%|█████████▉| 2182/2188 [4:18:18<00:34,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1451: 100%|█████████▉| 2182/2188 [4:18:19<00:34,  5.73s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1451: 100%|█████████▉| 2183/2188 [4:18:24<00:28,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5761: 100%|█████████▉| 2183/2188 [4:18:25<00:28,  5.75s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5761: 100%|█████████▉| 2184/2188 [4:18:30<00:23,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0485: 100%|█████████▉| 2184/2188 [4:18:31<00:23,  5.84s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0485: 100%|█████████▉| 2185/2188 [4:18:36<00:17,  6.00s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1455: 100%|█████████▉| 2185/2188 [4:18:37<00:17,  6.00s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1455: 100%|█████████▉| 2186/2188 [4:18:42<00:11,  5.92s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6120: 100%|█████████▉| 2186/2188 [4:18:43<00:11,  5.92s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6120: 100%|█████████▉| 2187/2188 [4:18:48<00:05,  5.86s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.7693: 100%|█████████▉| 2187/2188 [4:18:49<00:05,  5.86s/it]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.7693: 100%|██████████| 2188/2188 [4:18:53<00:00,  7.10s/it]\n",
      "Epoch 1 of 1: 100%|██████████| 1/1 [4:18:58<00:00, 15538.07s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2188, 0.4587006285700754)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "training_args = {\n",
    "    'num_train_epochs': 1,\n",
    "    'learning_rate': 0.005,\n",
    "    'overwrite_output_dir': True,\n",
    "    'evaluate_during_training': True,\n",
    "    'save_model_every_epoch': False\n",
    "}\n",
    "model.train_model(\n",
    "    subsets['train'],\n",
    "    eval_df=subsets['dev'],\n",
    "    output_dir=SAVE_PATH,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set consists of 17502 samples\nDev set consists of 2239 samples\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set consists of {len(subsets[\"train\"])} samples')\n",
    "print(f'Dev set consists of {len(subsets[\"dev\"])} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2239/2239 [00:39<00:00, 57.32it/s]\n",
      "Running Evaluation: 100%|██████████| 280/280 [11:02<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(subsets['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(output) for output in model_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       276\n           1       0.88      1.00      0.93      1963\n\n    accuracy                           0.88      2239\n   macro avg       0.44      0.50      0.47      2239\nweighted avg       0.77      0.88      0.82      2239\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(subsets['dev']['label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('norsk_kategorisering': pipenv)",
   "display_name": "Python 3.8.5 64-bit ('norsk_kategorisering': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "1530840518bfe90e79ffc7ae5ac3d5b93c02b0c0317a919e2cb3725fed8f5e19"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}